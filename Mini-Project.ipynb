{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Labels:  ['malignant' 'benign']\n",
      "Total No.of Instances (569, 30)\n",
      "The train data has 398 rows and 30 columns\n",
      "----------------------------\n",
      "The test data has 171 rows and 30 columns\n",
      "('mean radius', 0.031027406298215054)\n",
      "('mean texture', 0.01585780024538709)\n",
      "('mean perimeter', 0.04026314935128548)\n",
      "('mean area', 0.03830898128680701)\n",
      "('mean smoothness', 0.007018004000881229)\n",
      "('mean compactness', 0.014220852175901095)\n",
      "('mean concavity', 0.08177864251608798)\n",
      "('mean concave points', 0.13207193963018582)\n",
      "('mean symmetry', 0.00415787556137937)\n",
      "('mean fractal dimension', 0.004526104450902687)\n",
      "('radius error', 0.014438184615151863)\n",
      "('texture error', 0.005138341022710176)\n",
      "('perimeter error', 0.011561158427983192)\n",
      "('area error', 0.038344069133497645)\n",
      "('smoothness error', 0.004967848128208991)\n",
      "('compactness error', 0.005142839708485552)\n",
      "('concavity error', 0.007471585118162594)\n",
      "('concave points error', 0.006270845585102838)\n",
      "('symmetry error', 0.0046879812883628925)\n",
      "('fractal dimension error', 0.006678210834631949)\n",
      "('worst radius', 0.08700442940170988)\n",
      "('worst texture', 0.02119281639032628)\n",
      "('worst perimeter', 0.11718677719129128)\n",
      "('worst area', 0.09683874561974472)\n",
      "('worst smoothness', 0.01135976601253211)\n",
      "('worst compactness', 0.016832215476414)\n",
      "('worst concavity', 0.04268244929129558)\n",
      "('worst concave points', 0.11413658650606134)\n",
      "('worst symmetry', 0.010694585912865836)\n",
      "('worst fractal dimension', 0.008139808818428577)\n",
      "mean concave points\n",
      "worst perimeter\n",
      "worst concave points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9623115577889447"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "cancer = datasets.load_breast_cancer()\n",
    "print(\"Features: \", cancer.feature_names)\n",
    "print(\"Labels: \", cancer.target_names)\n",
    "feat_labels =['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    " 'mean smoothness', 'mean compactness', 'mean concavity',\n",
    " 'mean concave points', 'mean symmetry' ,'mean fractal dimension',\n",
    " 'radius error' ,'texture error' ,'perimeter error' ,'area error',\n",
    " 'smoothness error', 'compactness error', 'concavity error',\n",
    " 'concave points error', 'symmetry error' ,'fractal dimension error',\n",
    " 'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    " 'worst smoothness' ,'worst compactness', 'worst concavity',\n",
    " 'worst concave points', 'worst symmetry' ,'worst fractal dimension']\n",
    "print(\"Total No.of Instances\",cancer.data.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109)\n",
    "print ('The train data has {0} rows and {1} columns'.format(X_train.shape[0],X_train.shape[1]))\n",
    "print ('----------------------------')\n",
    "print ('The test data has {0} rows and {1} columns'.format(X_test.shape[0],X_test.shape[1]))\n",
    "clf=RandomForestClassifier(n_estimators=10000, random_state=0,n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "for feature in zip(feat_labels,clf.feature_importances_):\n",
    "    print(feature)\n",
    "sfm = SelectFromModel(clf,threshold=0.1)\n",
    "sfm.fit(X_train,y_train)\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n",
    "X_important_train=sfm.transform(X_train)\n",
    "X_important_test=sfm.transform(X_test)\n",
    "model = svm.SVC(kernel='linear', C=1, gamma=1) \n",
    "model.fit(X_train,y_train)\n",
    "predicted= model.predict(X_test)\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of all Features\n",
      "Train Accuracy: \n",
      " 0.9623115577889447\n",
      "Test Accuracy: \n",
      " 0.9649122807017544\n",
      "[[ 61   2]\n",
      " [  4 104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95        63\n",
      "          1       0.98      0.96      0.97       108\n",
      "\n",
      "avg / total       0.97      0.96      0.97       171\n",
      "\n",
      "precision:  0.9811320754716981\n",
      "recall:  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of all Features\")\n",
    "print('Train Accuracy: \\n', model.score(X_train, y_train))\n",
    "print('Test Accuracy: \\n', model.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(\"precision: \", metrics.precision_score(y_test, predicted))  \n",
    "print(\"recall: \", metrics.recall_score(y_test, predicted)) \n",
    "model2= svm.SVC(kernel='linear', C=1, gamma=1) \n",
    "model_important=model2.fit(X_important_train,y_train)\n",
    "important_predicted=model2.predict(X_important_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of selected Features\n",
      "Train Accuracy: \n",
      " 0.9095477386934674\n",
      "Test Accuracy: \n",
      " 0.9473684210526315\n",
      "[[ 61   2]\n",
      " [  4 104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.92      0.93        63\n",
      "          1       0.95      0.96      0.96       108\n",
      "\n",
      "avg / total       0.95      0.95      0.95       171\n",
      "\n",
      "precision:  0.9541284403669725\n",
      "recall:  0.9629629629629629\n",
      "[[ 58   5]\n",
      " [  4 104]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of selected Features\")\n",
    "model2.score(X_important_train, y_train)\n",
    "print('Train Accuracy: \\n', model2.score(X_important_train, y_train))\n",
    "print('Test Accuracy: \\n', model2.score(X_important_test,y_test))\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "print(classification_report(y_test, important_predicted))\n",
    "print(\"precision: \", metrics.precision_score(y_test, important_predicted))  \n",
    "print(\"recall: \", metrics.recall_score(y_test, important_predicted))\n",
    "print(confusion_matrix(y_test, important_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
